{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv('.env')\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\" \n",
    "You are a helpful bilingual tutor who is helping a 7-10 years old student learning a new language. \n",
    "Strictly take the following steps before you answer the student's question:\n",
    "\n",
    "1- Identify the native language of the student.\n",
    "2- Identify the intent of the student's question:\n",
    "    - Are they asking to practice the language they are learning through conversation?\n",
    "    - Are they asking for help to learn the langugage?\n",
    "3- Generate output based on the identified intent of the student's question.\n",
    "    - If the student is asking for help to learn the language, output your answer in their native language.\n",
    "    - If the student is asking to practice the language they are learning through conversation, output your answer in the language they are learning.\n",
    "\n",
    "Your tone should be friendly and encouraging.\n",
    "\n",
    "Now continue the conversation with the student, and strictly only output the answer to the student's question without explaining the thought process of the above steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Function to update conversation history\n",
    "def update_conversation_history(user_input, model_response):\n",
    "    # Store user input and model response as separate entries with their respective roles\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "\n",
    "# Function to construct the system message and combine it with the conversation history\n",
    "def get_conversation_messages():\n",
    "    # The system message that remains consistent throughout the conversation\n",
    "    system_message = {\"role\": \"system\", \"content\": sys_msg}\n",
    "    \n",
    "    # Return the system message along with the conversation history formatted for the API\n",
    "    # Limit the conversation history to the last 3 message pairs (user input, assistant response)\n",
    "    return [system_message] + conversation_history[-6:]\n",
    "\n",
    "# Function to query GPT-4 with user input and conversation history\n",
    "def query_gpt(user_input):\n",
    "    try:\n",
    "        # Get the conversation history formatted as API messages, including the system message\n",
    "        conversation_messages = get_conversation_messages()\n",
    "        \n",
    "        # Add the user's new input to the conversation\n",
    "        conversation_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # Make the API call to OpenAI's GPT model\n",
    "        response = client.chat.completions.create(\n",
    "            messages=conversation_messages,\n",
    "            model=\"gpt-4\",\n",
    "        )\n",
    "        # Extract the model's response\n",
    "        model_response = response.choices[0].message.content\n",
    "        \n",
    "        # Update conversation history with the model's response\n",
    "        update_conversation_history(user_input, model_response)\n",
    "        \n",
    "        return model_response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 你能教我怎么用spanish说吗\n",
      "ChatGPT: 当然可以，你可以说：“Me gusta comer pato laqueado de Pekín.”\n"
     ]
    }
   ],
   "source": [
    "user_input = \"你能教我怎么用spanish说吗\"\n",
    "print(\"User:\", user_input)\n",
    "response = query_gpt(user_input)\n",
    "print(\"ChatGPT:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to update conversation history\n",
    "def update_conversation_history(user_input, model_response):\n",
    "    conversation_history.append(f\"User: {user_input}\")\n",
    "    conversation_history.append(f\"AI: {model_response}\")\n",
    "\n",
    "# Function to construct the system prompt dynamically based on history\n",
    "def get_system_prompt():\n",
    "    history_prompt = \"\\n\".join(conversation_history)\n",
    "    return f\"You are ChatGPT. Here is the conversation history:\\n{history_prompt}\"\n",
    "\n",
    "# Function to query GPT-4 with user input and conversation history\n",
    "def query_gpt(user_input):\n",
    "    system_prompt = get_system_prompt()  # Construct prompt with history\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_input}]\n",
    "        )\n",
    "        # Extract the model's response\n",
    "        model_response = response['choices'][0]['message']['content']\n",
    "        # Update conversation history\n",
    "        update_conversation_history(user_input, model_response)\n",
    "        return model_response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example function to start a conversation\n",
    "def start_conversation():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = query_gpt(user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "# Main execution: starts a conversation loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start chatting with ChatGPT! Type 'exit' to quit.\")\n",
    "    start_conversation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
